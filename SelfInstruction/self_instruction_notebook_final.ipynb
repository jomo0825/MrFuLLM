{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Instruction Dataset Creation Example\n",
    "\n",
    "This notebook demonstrates how to create a dataset for fine-tuning language models using the Self-Instruction process, focusing on two task types: Sentiment Analysis and Question Answering (QA).\n",
    "\n",
    "The main steps of the Self-Instruction process are as follows:\n",
    "1. Prepare a small set of seed tasks  \n",
    "2. Use a large language model to generate additional tasks  \n",
    "3. Generate corresponding responses using the model  \n",
    "4. Filter and clean the generated data  \n",
    "5. Organize the final dataset for fine-tuning use  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install pandas tqdm numpy requests ollama matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up the Environment and Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# import openai\n",
    "import re\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set you OpenAI Key\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "model = \"gemma3:4b\"\n",
    "\n",
    "# Set the random seed to ensure reproducibility.\n",
    "random.seed(242)\n",
    "np.random.seed(242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We will create two types of seed tasks:\n",
    "- Sentiment Analysis\n",
    "- Question Answering (QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis Seed Tasks\n",
    "sentiment_seed_tasks = [\n",
    "    {\n",
    "        \"instruction\": \"Analyze the sentiment of the following review and determine whether it is positive, negative, or neutral. Provide your reasoning.\",\n",
    "        \"input\": \"The food at this restaurant was incredibly delicious, but the service was terrible—we waited an hour to be served.\",\n",
    "        \"output\": \"This review contains mixed sentiments. The positive aspect praises the food, while the negative aspect criticizes the slow and poor service. Overall, the review leans negative, as the service issues seem to have significantly impacted the dining experience.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Determine the sentiment tendency (positive, negative, or neutral) of the following text.\",\n",
    "        \"input\": \"The visual effects of the movie were stunning, but the plot was slow and lacked creativity.\",\n",
    "        \"output\": \"Negative. While the review acknowledges the movie’s visual appeal, the criticism of the plot is more significant, resulting in an overall negative impression.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Analyze the sentiment tone of this passage and categorize it as positive, negative, or neutral.\",\n",
    "        \"input\": \"The weather today is sunny and mild—perfect for outdoor activities.\",\n",
    "        \"output\": \"Positive. The description conveys pleasant weather conditions, expresses satisfaction, and suggests that the weather is ideal for being outdoors—overall a positive sentiment.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Determine the sentiment expressed in the following social media post.\",\n",
    "        \"input\": \"Another ordinary workday, same routine as usual, nothing special.\",\n",
    "        \"output\": \"Neutral. This post describes a routine day without expressing joy or dissatisfaction, reflecting a neutral emotional tone.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Analyze the following product review and determine the user’s sentiment toward the product.\",\n",
    "        \"input\": \"This phone has excellent battery life—it lasts a full two days on a single charge! The interface is also very intuitive. The camera is just average, but considering the price, I'm very satisfied.\",\n",
    "        \"output\": \"Positive. The review highlights strong points like long battery life and user-friendly interface. While it notes that the camera is average, the overall evaluation is positive, especially considering the price, showing clear positive sentiment.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# QA Seed Tasks\n",
    "qa_seed_tasks = [\n",
    "    {\n",
    "        \"instruction\": \"Answer the question based on the following paragraph.\",\n",
    "        \"input\": \"The solar system consists of the Sun and the celestial bodies that orbit it, including planets, moons, asteroids, and comets. There are eight major planets in order from the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Among them, Jupiter is the largest, and Earth is the only one known to support life.\\n\\nQuestion: Which planet is the largest in the solar system?\",\n",
    "        \"output\": \"Jupiter is the largest planet in the solar system.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Read the following and answer the question.\",\n",
    "        \"input\": \"Coffee is a beverage made from coffee beans and is known for its stimulating effect, mainly due to its caffeine content. Originating from the Ethiopian highlands, coffee later spread around the world. Today, the leading coffee-producing countries include Brazil, Vietnam, and Colombia. Common brewing methods include drip, espresso, French press, and cold brew.\\n\\nQuestion: Why does coffee have a stimulating effect?\",\n",
    "        \"output\": \"Coffee has a stimulating effect mainly because it contains caffeine.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Answer the following history question.\",\n",
    "        \"input\": \"World War I began in 1914, primarily triggered by the assassination of Archduke Franz Ferdinand of Austria-Hungary in Sarajevo. This event led Austria-Hungary to declare war on Serbia. Due to complex alliances, most major European nations were drawn into the conflict. The war ended in 1918 with a victory for the Allies and defeat for the Central Powers.\\n\\nQuestion: In what year did World War I begin?\",\n",
    "        \"output\": \"World War I began in 1914.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Answer the following question based on the provided information.\",\n",
    "        \"input\": \"The human digestive system is made up of several organs, including the mouth, esophagus, stomach, small intestine, large intestine, liver, and pancreas. Digestion begins in the mouth, where food is chewed and mixed with saliva. It then travels down the esophagus to the stomach, where it is further broken down by stomach acid. Most nutrients are absorbed in the small intestine, while undigested waste moves into the large intestine and is eventually excreted.\\n\\nQuestion: Where are most nutrients absorbed in the human body?\",\n",
    "        \"output\": \"Most nutrients in the human body are absorbed in the small intestine.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Read the following article excerpt and answer the question.\",\n",
    "        \"input\": \"Artificial Intelligence (AI) refers to intelligence demonstrated by machines, in contrast to natural intelligence shown by humans and animals. Modern AI technology primarily includes machine learning (especially deep learning), natural language processing, and computer vision. In recent years, AI has made significant advances in areas such as medical diagnosis, autonomous driving, and voice assistants, while also raising ethical concerns about privacy, employment, and safety.\\n\\nQuestion: What are the main areas included in modern AI technology?\",\n",
    "        \"output\": \"Modern AI technology mainly includes machine learning (especially deep learning), natural language processing, and computer vision.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for task in sentiment_seed_tasks:\n",
    "    task['task_type'] = \"sentiment\"\n",
    "for task in qa_seed_tasks:\n",
    "    task['task_type'] = \"qa\"\n",
    "# Combine All Seed Tasks\n",
    "seed_tasks = sentiment_seed_tasks + qa_seed_tasks\n",
    "\n",
    "# Display Task Counts\n",
    "print(f\"Number of Sentiment Analysis Seed Tasks: {len(sentiment_seed_tasks)}\")\n",
    "print(f\"Number of QA Seed Tasks: {len(qa_seed_tasks)}\")\n",
    "print(f\"Total Number of Seed Tasks: {len(seed_tasks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Functions to Generate New Task Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction(task_type, existing_instructions, max_retries=5):\n",
    "    \"\"\"\n",
    "    Generate a new task instruction using a large language model.\n",
    "    \n",
    "    Args:\n",
    "        task_type: 'sentiment' or 'qa'\n",
    "        existing_instructions: list of existing instructions to avoid duplication\n",
    "        max_retries: maximum number of retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing the newly generated instruction\n",
    "    \"\"\"\n",
    "    # Select the appropriate prompt template based on the task type\n",
    "    if task_type == \"sentiment\":\n",
    "        prompt_template = \"\"\"\n",
    "        You are an AI assistant helping to create a sentiment analysis dataset.\n",
    "        Please generate 5 new and diverse sentiment analysis instructions. \n",
    "        These instructions should ask users to determine the sentiment of a given text.\n",
    "\n",
    "        Here are some examples of existing instructions:\n",
    "        {examples}\n",
    "\n",
    "        Now generate new instructions that are different from the examples above.\n",
    "        Each instruction should clearly ask for sentiment classification.\n",
    "        The available classes are: positive, negative, and neutral.\n",
    "        \n",
    "        Return the result in JSON format, with each item being just the instruction text \n",
    "        (no input/output examples):\n",
    "        [\n",
    "            {{\"Instruction\": \"content number 1\"}},\n",
    "            {{\"Instruction\": \"content number 2\"}},\n",
    "            ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        examples = \"\\n\".join([f\"- {task['instruction']}\" for task in sentiment_seed_tasks])\n",
    "\n",
    "    elif task_type == \"qa\":\n",
    "        prompt_template = \"\"\"\n",
    "        You are an AI assistant helping to create a question-answering (QA) dataset.\n",
    "        Please generate 5 new and diverse QA instructions. These should prompt users to answer questions based on a given context.\n",
    "\n",
    "        Here are some examples of existing instructions:\n",
    "        {examples}\n",
    "\n",
    "        Now generate new instructions that differ from the examples above.\n",
    "        Each instruction should clearly ask for a context-based answer.\n",
    "\n",
    "        Return the result in JSON format, with each item being just the instruction text (no input/output examples):\n",
    "        [\n",
    "            {{\"Instruction\": \"content number 1\"}},\n",
    "            {{\"Instruction\": \"content number 2\"}},\n",
    "            ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        examples = \"\\n\".join([f\"- {task['instruction']}\" for task in qa_seed_tasks])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "    prompt = prompt_template.format(examples=examples)\n",
    "\n",
    "    # Attempt to generate new instructions\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model = model,\n",
    "                prompt= prompt,\n",
    "                options={\n",
    "                    \"temperature\": 1.0,\n",
    "                    \"seed\": np.random.randint(0, 10000)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            content = response['response'].strip()\n",
    "            json_match = re.search(r'\\[.*\\]', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                content = json_match.group(0)\n",
    "            new_instructions = json.loads(content)\n",
    "\n",
    "            if not isinstance(new_instructions, list):\n",
    "                print(f\"Attempt {attempt+1}/{max_retries}: Invalid return format, retrying...\")\n",
    "                continue\n",
    "                      \n",
    "            if isinstance(new_instructions[0], dict):\n",
    "                if \"Instruction\" in new_instructions[0]:\n",
    "                    new_instructions = [instr[\"Instruction\"] for instr in new_instructions]                    \n",
    "                else:\n",
    "                    print(f\"Attempt {attempt+1}/{max_retries}: Invalid return format, retrying...\")\n",
    "                    continue\n",
    "            \n",
    "            filtered_instructions = [instr for instr in new_instructions \n",
    "                                     if instr not in existing_instructions]\n",
    "\n",
    "            if not filtered_instructions:\n",
    "                print(f\"Attempt {attempt+1}/{max_retries}: All generated instructions already exist, retrying...\")\n",
    "                continue\n",
    "\n",
    "            selected_instruction = random.choice(filtered_instructions)\n",
    "            return {\"instruction\": selected_instruction, \"task_type\": task_type}, prompt\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1}/{max_retries} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            time.sleep(2)  # Pause briefly before retrying\n",
    "\n",
    "    raise Exception(\"Failed to generate new instruction after maximum retries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: generate instruction\n",
    "new_instruction_info, prompt = generate_instruction(\"sentiment\", [])\n",
    "output = f\"\"\"\n",
    "<span style='color: white; background-color: purple'>Prompt Template</span><br>\n",
    "<pre>{prompt}</pre>\n",
    "<span style='color: black; background-color: yellow'>Instruction</span><br>\n",
    "<pre>{new_instruction_info}</pre>\n",
    "\"\"\"\n",
    "display(HTML(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Functions to Generate Input Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input(task_instruction, task_type, max_retries=5):\n",
    "    \"\"\"\n",
    "    Generate input content based on a task instruction.\n",
    "    \n",
    "    Args:\n",
    "        task_instruction: The task instruction text\n",
    "        task_type: 'sentiment' or 'qa'\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        \n",
    "    Returns:\n",
    "        Generated input content\n",
    "    \"\"\"\n",
    "    # Select the appropriate prompt template based on the task type\n",
    "    if task_type == \"sentiment\":\n",
    "        prompt_template = \"\"\"\n",
    "        You are an AI assistant helping to create a sentiment analysis dataset. Given the following task instruction:\n",
    "\n",
    "        \"{instruction}\"\n",
    "\n",
    "        Please generate a suitable input text for this instruction. \n",
    "        The input should be a short passage requiring sentiment analysis related to {type}.\n",
    "\n",
    "        The input text should:\n",
    "        1. Be of moderate length (50–200 characters)\n",
    "        2. Sound natural and realistic\n",
    "        3. Convey a clear {sentiment_class} sentiment\n",
    "\n",
    "        Return only the input text itself—no explanations or additional formatting. No double quotes.\n",
    "        \"\"\"\n",
    "\n",
    "    elif task_type == \"qa\":\n",
    "        prompt_template = \"\"\"\n",
    "        You are an AI assistant helping to create a question-answering (QA) dataset. Given the following QA instruction:\n",
    "\n",
    "        \"{instruction}\"\n",
    "\n",
    "        Please generate a suitable input. The input should include:\n",
    "        1. A context paragraph rich in information (100–300 characters)\n",
    "        2. A question that can be clearly answered based on the provided context\n",
    "\n",
    "        The context can be related to science, history, culture, technology, health, or any other domain. The question must be directly answerable from the context.\n",
    "\n",
    "        Format your output as follows:\n",
    "        [Context paragraph]\n",
    "\n",
    "        Question: [Your question here]\n",
    "\n",
    "        Ensure that the question has a clear and direct answer in the context.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        instruction=task_instruction,\n",
    "        sentiment_class = random.choice([\"positive\", \"negative\", \"neutral\"]),\n",
    "        type=random.choice([\"social connection\", \"product\", \"weather\", \"sports\", \"investment\", \"school life\",\n",
    "                            \"book reading\", \"art critic\", \"traffic\"])\n",
    "    )\n",
    "\n",
    "    np.random.seed(int(time.time()))    # Attempt to generate input content\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model = model,\n",
    "                prompt= prompt,\n",
    "                options={\n",
    "                    \"temperature\": 1.0,\n",
    "                    \"seed\": np.random.randint(0, 10000),\n",
    "                    \"top_k\": 20,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            content = response['response'].strip().strip('\"')\n",
    "\n",
    "            # Basic validation\n",
    "            if len(content) < 20:\n",
    "                print(f\"Attempt {attempt+1}/{max_retries}: Input too short, retrying...\")\n",
    "                continue\n",
    "\n",
    "            if task_type == \"qa\" and \"Question:\" not in content:\n",
    "                print(f\"Attempt {attempt+1}/{max_retries}: Missing question part in QA input, retrying...\")\n",
    "                continue\n",
    "\n",
    "            return content, prompt\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1}/{max_retries} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            time.sleep(2)\n",
    "\n",
    "    raise Exception(\"Failed to generate input content after maximum retries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: generate input\n",
    "new_instruction_info, _ = generate_instruction(\"sentiment\", [])\n",
    "new_instruction = new_instruction_info[\"instruction\"]\n",
    "task_input, prompt = generate_input(new_instruction, \"sentiment\")\n",
    "output = f\"\"\"\n",
    "<span style='color: white; background-color: purple'>&nbsp;Prompt Template&nbsp;</span><br>\n",
    "<pre>{prompt}</pre>\n",
    "<span style='color: black; background-color: yellow'>&nbsp;Instruction&nbsp;</span><br>\n",
    "<pre>{new_instruction_info}</pre>\n",
    "<span style='color: black; background-color: cyan'>&nbsp;Input&nbsp;</span><br>\n",
    "<pre>{task_input}</pre>\n",
    "\"\"\"\n",
    "display(HTML(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Functions to Generate Output Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(task_instruction, task_input, task_type, max_retries=5):\n",
    "    \"\"\"\n",
    "    Generate output response based on the instruction and input.\n",
    "    \n",
    "    Args:\n",
    "        task_instruction: Task instruction text\n",
    "        task_input: Input content for the task\n",
    "        task_type: 'sentiment' or 'qa'\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        \n",
    "    Returns:\n",
    "        Generated output response\n",
    "    \"\"\"\n",
    "    # Choose an appropriate prompt template based on task type\n",
    "    if task_type == \"sentiment\":\n",
    "        prompt_template = \"\"\"\n",
    "        You are a professional sentiment analysis assistant. Based on the following instruction and input, generate a response:\n",
    "\n",
    "        Instruction:\n",
    "        {instruction}\n",
    "\n",
    "        Input Text:\n",
    "        {input}\n",
    "\n",
    "        Please provide a concise, professional sentiment analysis result that meets the requirements of the instruction. The response should clearly indicate the sentiment (positive, negative or neutral) and briefly explain the reasoning.\n",
    "\n",
    "        Return only the sentiment result as JSON object. Do not repeat the instruction or input text.\n",
    "        {{\n",
    "            \"Sentiment\": \"positive\",\n",
    "            \"Reason\": \"the reason for the judgement.\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "    elif task_type == \"qa\":\n",
    "        prompt_template = \"\"\"\n",
    "        You are a professional question-answering assistant. Based on the following instruction and input, generate a response:\n",
    "\n",
    "        Instruction:\n",
    "        {instruction}\n",
    "\n",
    "        Input:\n",
    "        {input}\n",
    "\n",
    "        Please provide a concise and accurate answer that directly addresses the question. The answer should be fully based on the given context, without adding any external information.\n",
    "\n",
    "        Return only your answer. Do not repeat the instruction, question, or context.\n",
    "        \"\"\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "    \n",
    "    # Fill the prompt\n",
    "    prompt = prompt_template.format(instruction=task_instruction, input=task_input)\n",
    "    \n",
    "    # Try to generate the output response\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model = model,\n",
    "                prompt= prompt,\n",
    "                options={\n",
    "                    \"temperature\": 1.0,\n",
    "                    \"seed\": np.random.randint(0, 10000)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            content = response['response'].strip()\n",
    "\n",
    "            if len(content) < 10:\n",
    "                print(f\"Attempt {attempt+1}/{max_retries}: Output too short, retrying...\")\n",
    "                continue\n",
    "\n",
    "            if task_type == \"sentiment\":\n",
    "                # if not any(keyword in content.lower() for keyword in [\"positive\", \"negative\", \"neutral\"]):\n",
    "                #     print(f\"Attempt {attempt+1}/{max_retries}: Sentiment label missing, retrying...\")\n",
    "                #     continue\n",
    "                json_output = extract_and_parse_json(content)\n",
    "                if not any (keyword in json_output[\"Sentiment\"].lower() for keyword in [\"positive\", \"negative\", \"neutral\"]):\n",
    "                    print(f\"Attempt {attempt+1}/{max_retries}: Sentiment label missing, retrying...\")\n",
    "                    continue\n",
    "                content = json.dumps(json_output)\n",
    "\n",
    "            return content\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1}/{max_retries} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            time.sleep(2)\n",
    "\n",
    "    raise Exception(\"Failed to generate output after maximum retries.\")\n",
    "\n",
    "\n",
    "def filter_task(task):\n",
    "    \"\"\"\n",
    "    Check whether the generated task meets quality requirements.\n",
    "    \n",
    "    Args:\n",
    "        task: Dictionary containing instruction, input, output, and task_type\n",
    "        \n",
    "    Returns:\n",
    "        Boolean: Whether the task passes filtering\n",
    "    \"\"\"\n",
    "    # Basic length check\n",
    "    if len(task[\"instruction\"]) < 10 or len(task[\"input\"]) < 20 or len(task[\"output\"]) < 10:\n",
    "        return False\n",
    "\n",
    "    # Check if output aligns with instruction and input\n",
    "    if task[\"task_type\"] == \"sentiment\":\n",
    "        if not any(keyword in task[\"output\"].lower() for keyword in [\"positive\", \"negative\", \"neutral\"]):\n",
    "            return False\n",
    "\n",
    "    elif task[\"task_type\"] == \"qa\":\n",
    "        question_text = \"\"\n",
    "        if \"Question:\" in task[\"input\"]:\n",
    "            parts = task[\"input\"].split(\"Question:\")\n",
    "            if len(parts) > 1:\n",
    "                question_text = parts[1].strip()\n",
    "\n",
    "        if question_text:\n",
    "            question_words = [w for w in question_text.replace(\"?\", \"\").replace(\"？\", \"\").split() if len(w) > 1]\n",
    "            if not any(word in task[\"output\"] for word in question_words):\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_task_hash(task):\n",
    "    \"\"\"\n",
    "    Generate a hash for the task to detect duplicates.\n",
    "    \n",
    "    Args:\n",
    "        task: Dictionary representing the task\n",
    "        \n",
    "    Returns:\n",
    "        A simple hash string for deduplication\n",
    "    \"\"\"\n",
    "    hash_str = f\"{task['instruction'][:50]}-{task['input'][:50]}\"\n",
    "    return hash(hash_str)\n",
    "\n",
    "def extract_and_parse_json(input_text):\n",
    "    # Extract content between ```json and ```\n",
    "    pattern = r'```json\\s*([\\s\\S]*?)\\s*```'\n",
    "    match = re.search(pattern, input_text)\n",
    "    if match:\n",
    "        json_content = match.group(1)\n",
    "        # Parse the extracted JSON string\n",
    "        return json.loads(json_content)\n",
    "    raise ValueError(\"No JSON found between ```json and ``` tags\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: generate output\n",
    "new_instruction_info, prompt = generate_instruction(\"sentiment\", [])\n",
    "new_instruction = new_instruction_info[\"instruction\"]\n",
    "task_input, prompt = generate_input(new_instruction, \"sentiment\")\n",
    "task_output = generate_output(new_instruction, task_input, \"sentiment\")\n",
    "output = f\"\"\"\n",
    "<span style='color: white; background-color: purple'>&nbsp;Prompt Template&nbsp;</span><br>\n",
    "<pre>{prompt}</pre>\n",
    "<span style='color: black; background-color: yellow'>&nbsp;Instruction&nbsp;</span><br>\n",
    "<pre>{new_instruction_info}</pre>\n",
    "<span style='color: black; background-color: cyan'>&nbsp;Input&nbsp;</span><br>\n",
    "<pre>{task_input}</pre>\n",
    "<span style='color: black; background-color: magenta'>&nbsp;Output&nbsp;</span><br>\n",
    "<pre>{task_output}</pre>\n",
    "\"\"\"\n",
    "display(HTML(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Procedure: Creating a Self-Instruction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_self_instruction_dataset(num_tasks=50, task_distribution={\"sentiment\": 0.5, \"qa\": 0.5}):\n",
    "    \"\"\"\n",
    "    Create a Self-Instruction dataset.\n",
    "    \n",
    "    Args:\n",
    "        num_tasks: Total number of tasks to generate\n",
    "        task_distribution: Proportional distribution of task types\n",
    "        \n",
    "    Returns:\n",
    "        A list of generated tasks\n",
    "    \"\"\"\n",
    "    # Initialize result list with all seed tasks\n",
    "    #tasks = seed_tasks.copy()\n",
    "    tasks = []\n",
    "    \n",
    "    # Collect existing instructions to avoid duplicates\n",
    "    existing_instructions = set([task[\"instruction\"] for task in tasks])\n",
    "    \n",
    "    # Set for detecting duplicates based on hash\n",
    "    task_hashes = set([get_task_hash(task) for task in tasks])\n",
    "    \n",
    "    # Task type list and their respective weights\n",
    "    task_types = list(task_distribution.keys())\n",
    "    task_weights = list(task_distribution.values())\n",
    "    \n",
    "    # Calculate how many new tasks are needed\n",
    "    num_new_tasks = num_tasks - len(tasks)\n",
    "    \n",
    "    # Generate new tasks one by one\n",
    "    pbar = tqdm(total=num_new_tasks, desc=\"Generating Tasks\")\n",
    "    \n",
    "    while len(tasks) < num_tasks:\n",
    "        try:\n",
    "            # Choose task type based on distribution\n",
    "            task_type = random.choices(task_types, weights=task_weights, k=1)[0]\n",
    "            \n",
    "            # Generate new instruction\n",
    "            new_instruction_info, _ = generate_instruction(task_type, existing_instructions)\n",
    "            new_instruction = new_instruction_info[\"instruction\"]\n",
    "            existing_instructions.add(new_instruction)\n",
    "            \n",
    "            # Generate input\n",
    "            task_input, _ = generate_input(new_instruction, task_type)\n",
    "            \n",
    "            # Generate output\n",
    "            task_output = generate_output(new_instruction, task_input, task_type)\n",
    "            \n",
    "            # Create full task\n",
    "            new_task = {\n",
    "                \"instruction\": new_instruction,\n",
    "                \"input\": task_input,\n",
    "                \"output\": task_output,\n",
    "                \"task_type\": task_type\n",
    "            }\n",
    "            \n",
    "            # Compute task hash to detect duplication\n",
    "            task_hash = get_task_hash(new_task)\n",
    "            \n",
    "            # Check quality and duplication\n",
    "            if filter_task(new_task) and task_hash not in task_hashes:\n",
    "                tasks.append(new_task)\n",
    "                task_hashes.add(task_hash)\n",
    "                pbar.update(1)\n",
    "            else:\n",
    "                print(\"Task failed quality check or is duplicate. Regenerating...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during task generation: {e}\")\n",
    "            time.sleep(1)  # Pause briefly before retrying\n",
    "    \n",
    "    pbar.close()\n",
    "    return tasks\n",
    "\n",
    "\n",
    "# Generate a small sample dataset (use larger numbers in practice)\n",
    "# For demonstration and testing purposes, we'll generate a small number of tasks here\n",
    "dataset = create_self_instruction_dataset(num_tasks=10, task_distribution={\"sentiment\": 0.5, \"qa\": 0.5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze and Visualize the Generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"Total number of tasks in the dataset: {len(df)}\")\n",
    "print(\"\\nNumber of tasks by type:\")\n",
    "print(df['task_type'].value_counts())\n",
    "\n",
    "# Calculate average lengths of instruction, input, and output\n",
    "df['instruction_len'] = df['instruction'].apply(len)\n",
    "df['input_len'] = df['input'].apply(len)\n",
    "df['output_len'] = df['output'].apply(len)\n",
    "\n",
    "print(\"\\nAverage Length Statistics:\")\n",
    "print(f\"Average instruction length: {df['instruction_len'].mean():.1f} characters\")\n",
    "print(f\"Average input length: {df['input_len'].mean():.1f} characters\")\n",
    "print(f\"Average output length: {df['output_len'].mean():.1f} characters\")\n",
    "\n",
    "# Grouped statistics by task type\n",
    "print(\"\\nAverage Lengths by Task Type:\")\n",
    "type_stats = df.groupby('task_type').agg({\n",
    "    'instruction_len': 'mean',\n",
    "    'input_len': 'mean',\n",
    "    'output_len': 'mean'\n",
    "}).round(1)\n",
    "print(type_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Dataset Distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Task type distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(data=df, x='task_type')\n",
    "plt.title('Task Type Distribution')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Instruction length distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(data=df, x='instruction_len', hue='task_type', bins=10, kde=True)\n",
    "plt.title('Instruction Length Distribution')\n",
    "plt.xlabel('Number of Characters')\n",
    "\n",
    "# Input length distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(data=df, x='input_len', hue='task_type', bins=10, kde=True)\n",
    "plt.title('Input Length Distribution')\n",
    "plt.xlabel('Number of Characters')\n",
    "\n",
    "# Output length distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(data=df, x='output_len', hue='task_type', bins=10, kde=True)\n",
    "plt.title('Output Length Distribution')\n",
    "plt.xlabel('Number of Characters')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('dataset_analysis.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sample Review and Inspection\n",
    "\n",
    "Let’s randomly examine some of the generated task examples to check their quality and ensure diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a few Sentiment Analysis task examples\n",
    "sentiment_samples = df[df['task_type'] == 'sentiment'].sample(n=2, random_state=42)\n",
    "\n",
    "# Randomly sample a few QA task examples\n",
    "qa_samples = df[df['task_type'] == 'qa'].sample(n=2, random_state=42)\n",
    "\n",
    "# Display Sentiment Analysis examples\n",
    "print(\"Sentiment Analysis Task Examples:\")\n",
    "for i, (_, row) in enumerate(sentiment_samples.iterrows(), 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Instruction: {row['instruction']}\")\n",
    "    print(f\"Input: {row['input']}\")\n",
    "    print(f\"Output: {row['output']}\")\n",
    "\n",
    "# Display QA examples\n",
    "print(\"\\n\\nQA Task Examples:\")\n",
    "for i, (_, row) in enumerate(qa_samples.iterrows(), 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Instruction: {row['instruction']}\")\n",
    "    print(f\"Input: {row['input']}\")\n",
    "    print(f\"Output: {row['output']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Dataset\n",
    "\n",
    "Save the generated dataset in JSON format for use in fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove auxiliary length columns\n",
    "df_export = df.drop(columns=['instruction_len', 'input_len', 'output_len'])\n",
    "\n",
    "# Convert to fine-tuning format\n",
    "export_data = df_export.to_dict(orient='records')\n",
    "\n",
    "# Save as JSON file\n",
    "output_file = \"dataset_self_instruction.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Dataset saved to: {output_file}\")\n",
    "\n",
    "# Save another version formatted for OpenAI fine-tuning\n",
    "openai_format = []\n",
    "for item in export_data:\n",
    "    openai_format.append({\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": item[\"instruction\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": item[\"input\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": item[\"output\"]\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "\n",
    "openai_output_file = \"dataset_self_instruction_openai.json\"\n",
    "with open(openai_output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(openai_format, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"OpenAI-formatted dataset saved to: {openai_output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dataset Expansion and Improvement Suggestions\n",
    "\n",
    "This notebook demonstrates a basic Self-Instruction workflow focused on sentiment analysis and QA tasks. To further expand and enhance this dataset, consider the following recommendations:\n",
    "\n",
    "1. **Increase Task Type Diversity**:  \n",
    "   Beyond sentiment analysis and QA, include tasks such as text classification, named entity recognition, summarization, etc.\n",
    "\n",
    "2. **Add Complexity**:  \n",
    "   Gradually incorporate more complex tasks like multi-step reasoning or comparative analysis.\n",
    "\n",
    "3. **Improve Quality Filtering**:  \n",
    "   Develop stricter quality filtering mechanisms to ensure that generated instructions are clear, inputs are appropriate, and outputs are accurate.\n",
    "\n",
    "4. **Incorporate Human Review**:  \n",
    "   As the dataset grows, introduce a human review step to assess and refine the quality of generated content.\n",
    "\n",
    "5. **Support Multiple Languages**:  \n",
    "   Expand to other languages to build a multilingual Self-Instruction dataset.\n",
    "\n",
    "6. **Domain Specialization**:  \n",
    "   Create domain-specific task sets tailored to fields like medicine, law, finance, etc.\n",
    "\n",
    "7. **Use More Varied Text Sources**:  \n",
    "   Source input texts from diverse content types and platforms to improve variety.\n",
    "\n",
    "8. **Iterative Refinement**:  \n",
    "   Use a model fine-tuned on the current Self-Instruction dataset to generate the next round of tasks, enabling progressive enhancement.\n",
    "\n",
    "9. **Experiment with Task Distribution**:  \n",
    "   Adjust the proportions of different task types to study their impact on model performance.\n",
    "\n",
    "10. **Seed with Manually Crafted High-Quality Examples**:  \n",
    "    Incorporate more high-quality, human-written seed examples to boost overall generation quality. \n",
    "\n",
    "Let me know if you’d like to explore any of these directions with sample code or implementation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "Self-instruction is an effective technique that leverages a small amount of high-quality, manually labeled data to generate a large number of training examples. This notebook demonstrated the complete process of using this approach to create datasets for sentiment analysis and QA tasks.\n",
    "\n",
    "Through this method, we can:\n",
    "- Significantly reduce reliance on manual annotation  \n",
    "- Rapidly generate diverse instruction–response pairs  \n",
    "- Create more targeted, task-specific datasets  \n",
    "- Continuously expand and update datasets over time  \n",
    "\n",
    "This approach is particularly well-suited for fine-tuning large language models, enabling them to better follow a wide range of instructions and produce useful outputs. As model capabilities and generation quality improve, self-instruction can foster a positive feedback loop—continually enhancing the model’s ability to understand and follow instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
